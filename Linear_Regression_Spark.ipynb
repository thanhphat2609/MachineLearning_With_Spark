{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b57064",
   "metadata": {},
   "source": [
    "# 1. Import necessary libraries #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1acbaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#import functions/Classes for sparkml\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# import functions/Classes for metrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647000f0",
   "metadata": {},
   "source": [
    "# 2. Create spark session and load data into dataframe #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126f9326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/15 01:21:17 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"LinearRegressionwithSpark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad211e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(MPG=15.0, Cylinders=8, Engine Disp=390.0, Horsepower=190, Weight=3850, Accelerate=8.5, Year=70, Origin='American'),\n",
       " Row(MPG=21.0, Cylinders=6, Engine Disp=199.0, Horsepower=90, Weight=2648, Accelerate=15.0, Year=70, Origin='American'),\n",
       " Row(MPG=18.0, Cylinders=6, Engine Disp=199.0, Horsepower=97, Weight=2774, Accelerate=15.5, Year=70, Origin='American'),\n",
       " Row(MPG=16.0, Cylinders=8, Engine Disp=304.0, Horsepower=150, Weight=3433, Accelerate=12.0, Year=70, Origin='American'),\n",
       " Row(MPG=14.0, Cylinders=8, Engine Disp=455.0, Horsepower=225, Weight=3086, Accelerate=10.0, Year=70, Origin='American')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data in csv file into dataframe\n",
    "df_mpg = spark.read.csv(\"../dataset/mpg.csv\", header = True, inferSchema = True)\n",
    "df_mpg.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8316e63",
   "metadata": {},
   "source": [
    "# 3. Identify the label column and the input columns #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55c9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature vector to create Features\n",
    "    # \"Cylinders\", \"Engine Disp\", \"Horsepower\", \"Weight\", \"Accelerate\", \"Year\" => Features\n",
    "    # \"MPG\" => Target\n",
    "assembler = VectorAssembler(inputCols = [\"Cylinders\", \"Engine Disp\", \"Horsepower\", \"Weight\", \"Accelerate\", \"Year\"]\n",
    "                            , outputCol = \"features\")\n",
    "mpg_transformed_data = assembler.transform(df_mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b04369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features| MPG|\n",
      "+--------------------+----+\n",
      "|[8.0,390.0,190.0,...|15.0|\n",
      "|[6.0,199.0,90.0,2...|21.0|\n",
      "|[6.0,199.0,97.0,2...|18.0|\n",
      "|[8.0,304.0,150.0,...|16.0|\n",
      "|[8.0,455.0,225.0,...|14.0|\n",
      "|[8.0,350.0,165.0,...|15.0|\n",
      "|[8.0,307.0,130.0,...|18.0|\n",
      "|[8.0,454.0,220.0,...|14.0|\n",
      "|[8.0,400.0,150.0,...|15.0|\n",
      "|[8.0,307.0,200.0,...|10.0|\n",
      "|[8.0,383.0,170.0,...|15.0|\n",
      "|[8.0,318.0,210.0,...|11.0|\n",
      "|[8.0,360.0,215.0,...|10.0|\n",
      "|[8.0,429.0,198.0,...|15.0|\n",
      "|[6.0,200.0,85.0,2...|21.0|\n",
      "|[8.0,302.0,140.0,...|17.0|\n",
      "|[8.0,304.0,193.0,...| 9.0|\n",
      "|[8.0,340.0,160.0,...|14.0|\n",
      "|[6.0,198.0,95.0,2...|22.0|\n",
      "|[8.0,440.0,215.0,...|14.0|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg_transformed_data.select(\"features\", \"MPG\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4220b3",
   "metadata": {},
   "source": [
    "# 4. Split dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691a9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "(training_data, testing_data) = mpg_transformed_data.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455e0d2c",
   "metadata": {},
   "source": [
    "# 5. Build and train Linear Regression model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4865bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/15 01:21:21 WARN Instrumentation: [3b66a703] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "# Create instance of Linear Regression\n",
    "lr = LinearRegression(featuresCol = \"features\", labelCol = \"MPG\")\n",
    "\n",
    "# Train model\n",
    "model = lr.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d6b26",
   "metadata": {},
   "source": [
    "# 6. Evaluate model # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650031eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on testing data\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281e7334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 3.4531049690792326\n"
     ]
    }
   ],
   "source": [
    "#Root Mean Squared Error (RMSE): RMSE is the square root of the average of the squared differences\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"MPG\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e3bd288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared = 0.8046190375720306\n"
     ]
    }
   ],
   "source": [
    "#R-squared (R2): R2 is a statistical measure that represents the proportion of variance\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"MPG\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R Squared =\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2195c468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 2.8423911791950265\n"
     ]
    }
   ],
   "source": [
    "#Mean Absolute Error (MAE): MAE is the average of the absolute differences between the predicted and actual values\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"MPG\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(\"MAE =\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a29bd",
   "metadata": {},
   "source": [
    "# 7. Stop Spark Session #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1965ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
